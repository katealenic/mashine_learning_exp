{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Wasserstein_gan_gradient_penalty.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LG1gGmutD1Bs","colab_type":"code","outputId":"3c67de89-2bff-4d2f-bb2e-130d0de47463","executionInfo":{"status":"ok","timestamp":1576578938670,"user_tz":-180,"elapsed":734,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hXk1ibmD6c8","colab_type":"code","outputId":"6dc20de2-a7b7-4f7a-ad12-b58c73497739","executionInfo":{"status":"ok","timestamp":1576578940307,"user_tz":-180,"elapsed":926,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/gdrive/My Drive/my_data/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/my_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OKMhNoZID6h3","colab_type":"code","colab":{}},"source":["from numpy import expand_dims,mean,ones\n","\n","from numpy.random import randn,randint\n","from keras.datasets.mnist import load_data\n","from keras import backend as K\n","from keras.optimizers import RMSprop\n","from keras.models import Model\n","from keras.layers import Dense,Reshape,Flatten,Conv2D,Conv2DTranspose\n","from keras.layers import LeakyReLU,BatchNormalization,Input, Dropout\n","\n","from keras.initializers import RandomNormal\n","from keras.constraints import Constraint\n","from matplotlib import pyplot\n","from functools import partial"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LuaAxfLID6mr","colab_type":"code","outputId":"9dfa8aec-b29c-4e66-ae58-7a0532fcc468","executionInfo":{"status":"ok","timestamp":1576578944260,"user_tz":-180,"elapsed":630,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.utils import conv_utils\n","class Conv2DTransposeTest(Conv2DTranspose):\n","    \n","    def call(self, inputs):\n","        input_shape = K.shape(inputs)\n","        batch_size = input_shape[0]\n","        if self.data_format == 'channels_first':\n","            h_axis, w_axis = 2, 3\n","        else:\n","            h_axis, w_axis = 1, 2\n","\n","        height, width = input_shape[h_axis], input_shape[w_axis]\n","        kernel_h, kernel_w = self.kernel_size\n","        stride_h, stride_w = self.strides\n","        if self.output_padding is None:\n","            out_pad_h = out_pad_w = None\n","        else:\n","            out_pad_h, out_pad_w = self.output_padding\n","\n","        # Infer the dynamic output shape:\n","        out_height = conv_utils.deconv_length(height,\n","                                              stride_h, kernel_h,\n","                                              self.padding,\n","                                              out_pad_h,\n","                                              self.dilation_rate[0])\n","        out_width = conv_utils.deconv_length(width,\n","                                             stride_w, kernel_w,\n","                                             self.padding,\n","                                             out_pad_w,\n","                                             self.dilation_rate[1])\n","        if self.data_format == 'channels_first':\n","            output_shape = (batch_size, self.filters, out_height, out_width)\n","        else:\n","            output_shape = (batch_size, out_height, out_width, self.filters)\n","\n","        outputs = K.conv2d_transpose(\n","            inputs,\n","            self.kernel/(K.epsilon() + K.sum(self.kernel**2)),\n","            output_shape,\n","            self.strides,\n","            padding=self.padding,\n","            data_format=self.data_format,\n","            dilation_rate=self.dilation_rate)\n","\n","        if self.use_bias:\n","            outputs = K.bias_add(\n","                outputs,\n","                self.bias,\n","                data_format=self.data_format)\n","\n","        if self.activation is not None:\n","            return self.activation(outputs)\n","        return outputs\n","\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"veb2gfhWD6r4","colab_type":"code","colab":{}},"source":["# clip model weights to a given hypercube\n","class ClipConstraint(Constraint):\n","\t# set clip value when initialized\n","\tdef __init__(self, clip_value):\n","\t\tself.clip_value = clip_value\n"," \n","\t# clip model weights to hypercube\n","\tdef __call__(self, weights):\n","\t\treturn K.clip(weights, -self.clip_value, self.clip_value)\n"," \n","\t# get the config\n","\tdef get_config(self):\n","\t\treturn {'clip_value': self.clip_value}\n"," \n","# calculate wasserstein loss\n","def wasserstein_loss(y_true, y_pred):\n","\treturn K.mean(y_true * y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gL5uym4FOJ1","colab_type":"code","colab":{}},"source":["# define the standalone critic model\n","def define_critic(in_shape=(64,64,3)):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.001)\n","  # weight constraint\n","  const = ClipConstraint(0.001)\n","  in_layer = Input(shape = in_shape)\n","  c_layer = in_layer\n","  # downsample to 14x14\n","  c_layer = Conv2D(64*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","  c_layer = Dropout(0.25)(c_layer)\n","\t# downsample to 7x7\n","  c_layer = Conv2D(64*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","  c_layer = Dropout(0.25)(c_layer)\n","  # downsample to 7x7\n","  c_layer = Conv2D(64*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","  c_layer = Dropout(0.25)(c_layer)\n","\t# scoring, linear activation\n","  c_layer = Flatten()(c_layer)\n","  c_layer = Dense(1)(c_layer)\n","\t# compile model\n","  model = Model(in_layer, c_layer, name = 'define_critic')\n","  opt = RMSprop(lr=0.00005)\n","  \n","  model.compile(loss=wasserstein_loss, optimizer=opt)\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYRGYK5mFOQD","colab_type":"code","colab":{}},"source":["# define the standalone generator model\n","def define_generator(latent_dim):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.001)\n","  #const = ClipConstraint(0.001)\n","  # define model\n","  in_layer = Input(shape = (latent_dim,))\n","  c_layer = in_layer\n","  # foundation for 8x8 image\n","  n_nodes = 128 * 8 * 8 * 3 \n","  c_layer = Dense(n_nodes, kernel_initializer=init)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","  c_layer = Reshape((8, 8, 128*3))(c_layer)\n","  # upsample to 16x16\n","  c_layer = Conv2DTranspose(128*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","  # upsample to 32x32\n","  c_layer = Conv2DTranspose(128*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","    # upsample to 64x64\n","  c_layer = Conv2DTranspose(128*3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(c_layer)\n","  c_layer = BatchNormalization(momentum=0.999)(c_layer)\n","  c_layer = LeakyReLU(alpha=0.2)(c_layer)\n","\n","  c_layer = Conv2D(3, (8,8), activation='tanh', padding='same', kernel_initializer=init)(c_layer)\n","  model = Model(in_layer, c_layer, name = 'define_generator')\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nAloxA_FOW3","colab_type":"code","colab":{}},"source":["import numpy as np\n","# load images\n","def load_real_samples():\n","\t# load dataset\n","\n","  data_frames = np.load('frames_64x64.npy')\n","\t# convert from ints to floats\n","  data_frames = data_frames.astype('float32')\n","\t# scale from [0,255] to [-1,1]\n","  data_frames = (data_frames - 127.5) / 127.5\n","  return data_frames\n","\n","  # select real samples\n","def generate_real_samples(dataset, n_samples):\n","\t# choose random instances\n","\tix = randint(0, dataset.shape[0], n_samples)\n","\t# select images\n","\tX = dataset[ix]\n","\t# generate class labels, -1 for 'real'\n","\ty = -ones((n_samples, 1))\n","\treturn X, y\n","\n","  # generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape(n_samples, latent_dim)\n","\treturn x_input\n"," \n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","\t# generate points in latent space\n","\tx_input = generate_latent_points(latent_dim, n_samples)\n","\t# predict outputs\n","\tX = generator.predict(x_input)\n","\t# create class labels with 1.0 for 'fake'\n","\ty = ones((n_samples, 1))\n","\treturn X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWmx6hvBD6xt","colab_type":"code","colab":{}},"source":["from IPython.display import clear_output\n","# generate samples and save as a plot and save the model\n","def summarize_performance(step, g_model, latent_dim, n_samples=100):\n","  clear_output()\n","\t# prepare fake examples\n","  X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n","\t# scale from [-1,1] to [0,1]\n","  X = (X + 1) / 2.0\n","\t# plot images\n","  for i in range(10 * 10):\n","\t\t# define subplot\n","    pyplot.subplot(10, 10, 1 + i)\n","\t\t# turn off axis\n","    pyplot.axis('off')\n","\t\t# plot raw pixel data\n","    pyplot.imshow(X[i])\n","\t# save plot to file\n","  pyplot.show()\n","\t# save the generator model\n","\t\n","\t\n"," \n","# create a line plot of loss for the gan and save to file\n","def plot_history(d1_hist, d2_hist, g_hist):\n","\t# plot history\n","\tpyplot.plot(d1_hist, label='crit_real')\n","\tpyplot.plot(d2_hist, label='crit_fake')\n","\tpyplot.plot(g_hist, label='gen')\n","\tpyplot.legend()\n","\tpyplot.savefig('plot_line_plot_loss2.png')\n","\tpyplot.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bwn_B3ZBFY7J","colab_type":"code","colab":{}},"source":["# train the generator and critic\n","def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n","  # calculate the number of batches per training epoch\n","  bat_per_epo = int(dataset.shape[0] / n_batch)\n","  # calculate the number of training iterations\n","  n_steps = bat_per_epo * n_epochs\n","  # calculate the size of half a batch of samples\n","  half_batch = int(n_batch )\n","  # lists for keeping track of loss\n","  c1_hist, c2_hist, g_hist = list(), list(), list()\n","  # manually enumerate epochs\n","  for i in range(n_steps):\n","    c1_tmp, c2_tmp = list(), list()\n","    c_model.trainable = True\n","    g_model.trainable = False\n","\n","    for _ in range(n_critic):\n","\t\t\t# get randomly selected 'real' samples\n","      X_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t\t# update critic model weights\n","      c_loss1 = c_model.train_on_batch(X_real, y_real)\n","      c1_tmp.append(c_loss1)\n","\t\t\t# generate 'fake' examples\n","      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","\t\t\t# update critic model weights\n","      c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n","      c2_tmp.append(c_loss2)\n","\n","    c_model.trainable = False\n","    g_model.trainable = True\n","    # store critic loss\n","    c1_hist.append(mean(c1_tmp))\n","    c2_hist.append(mean(c2_tmp))\n","    X_real, y_real = generate_real_samples(dataset, n_batch)\n","    # prepare points in latent space as input for the generator\n","    X_gan = generate_latent_points(latent_dim, n_batch)\n","    # create inverted labels for the fake samples\n","    y_gan = -ones((n_batch, 1))\n","    # update the generator via the critic's error\n","    g_loss = gan_model.train_on_batch([X_gan,X_real], [y_real,y_gan,y_real])\n","    g_hist.append(g_loss[1])\n","    # summarize loss on this batch\n","    print('>%d, c1=%.3f, c2=%.3f g=%.3f pg=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss[1],g_loss[2]))\n","    # evaluate the model performance every 'epoch'\n","    if (i+1) % bat_per_epo == 0:\n","      summarize_performance(i, g_model, latent_dim)\n","  # line plots of loss\n","  plot_history(c1_hist, c2_hist, g_hist)\n"," \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4yfboMORANH","colab_type":"code","colab":{}},"source":["def train_new(g_model, c_model, critic_model,generator_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n","  sample_interval=50\n","  valid = -np.ones((n_batch, 1))\n","  fake =  np.ones((n_batch, 1))\n","  dummy = np.zeros((n_batch, 1))\n","  half_batch = int(n_batch )\n","  for epoch in range(n_epochs):\n","    for _ in range(n_critic):\n","      # ---------------------\n","      #  Train Discriminator\n","      # ---------------------\n","      \n","      imgs, _ = generate_real_samples(dataset, half_batch)\n","      noise = generate_latent_points(latent_dim, half_batch)\n","      # Train the critic\n","      d_loss = critic_model.train_on_batch([imgs, noise],[valid, fake, dummy])\n","\n","      # ---------------------\n","      #  Train Generator\n","      # ---------------------\n","    noise = generate_latent_points(latent_dim, n_batch)\n","    g_loss = generator_model.train_on_batch(noise, valid)\n","    # Plot the progress\n","    print (\"%d [C loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n","    # If at save interval => save generated image samples\n","    if epoch % sample_interval == 0:\n","      summarize_performance(i, g_model, latent_dim)\n","\n"," \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoTFCqsLPAtK","colab_type":"code","colab":{}},"source":["def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n","  gradients = K.gradients(y_pred, averaged_samples)[0]\n","  # compute the euclidean norm by squaring ...\n","  gradients_sqr = K.square(gradients)\n","  #   ... summing over the rows ...\n","  gradients_sqr_sum = K.sum(gradients_sqr,axis=np.arange(1, len(gradients_sqr.shape)))\n","  #   ... and sqrt\n","  gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n","  # compute lambda * (1 - ||grad||)^2 still for each single sample\n","  gradient_penalty = K.square(1 - gradient_l2_norm)\n","  # return the mean as loss over all the batch samples\n","  return K.mean(gradient_penalty)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUbLkTE2LSlW","colab_type":"code","colab":{}},"source":["def _compute_gradients(tensor, var_list):\n","  grads = K.gradients(tensor, var_list)\n","  return [grad if grad is not None else K.zeros_like(var) for var, grad in zip(var_list, grads)]\n","#r1/r2 gradient penalty\n","def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n","    gradients = _compute_gradients(y_pred, [averaged_samples])[0]\n","    gradients_sqr = K.square(gradients)\n","    gradient_penalty = K.sum(gradients_sqr,\n","                              axis=np.arange(1, len(gradients_sqr.shape)))\n","    \n","    return K.mean(gradient_penalty * weight)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvobO2T0sQfh","colab_type":"code","colab":{}},"source":["from keras.layers.merge import _Merge\n","class RandomWeightedAverage(_Merge):\n","    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n","    def _merge_function(self, inputs):\n","        alpha = K.random_uniform((32, 1, 1, 1))\n","        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"78aEPf5Urq65","colab_type":"code","outputId":"83441e32-3ec2-4779-8c7c-ea311f4b2180","executionInfo":{"status":"error","timestamp":1576584812689,"user_tz":-180,"elapsed":314650,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":558}},"source":["critic.trainable = False\n","latent_dim = 300\n","\n","# create the critic\n","critic = define_critic()\n","# create the generator\n","generator = define_generator(latent_dim)\n","\n","real_img = Input(shape=(64,64,3))\n","z_disc = Input(shape=(latent_dim,))\n","fake_img = generator(z_disc)\n","\n","fake = critic(fake_img)\n","valid = critic(real_img)\n","\n","interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n","validity_interpolated = critic(interpolated_img)\n","\n","partial_gp_loss = partial(gradient_penalty_loss, averaged_samples=interpolated_img)\n","partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n","\n","critic_model = Model(inputs=[real_img, z_disc], outputs=[valid, fake, validity_interpolated])\n","opt = RMSprop(lr=0.00001)\n","critic_model.compile(loss=[wasserstein_loss,\n","                           wasserstein_loss,\n","                           partial_gp_loss],\n","                     optimizer=opt,\n","                     loss_weights=[1, 1, 10])\n","\n","critic.trainable = False\n","generator.trainable = True\n","z_gen = Input(shape=(latent_dim,))\n","img = generator(z_gen)\n","valid = critic(img)\n","generator_model = Model(z_gen, valid)\n","generator_model.compile(loss=wasserstein_loss, optimizer=opt)\n","\n","dataset = load_real_samples()\n","print(dataset.shape)\n","\n","# train model\n","train_new(generator, critic, critic_model,generator_model, dataset, latent_dim,n_epochs=50, n_batch=32, n_critic=5)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2503, 64, 64, 3)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [C loss: 3.444063] [G loss: 0.028246]\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-922b4b6581f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-40-879c2b2c5bb7>\u001b[0m in \u001b[0;36mtrain_new\u001b[0;34m(g_model, c_model, critic_model, generator_model, dataset, latent_dim, n_epochs, n_batch, n_critic)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# If at save interval => save generated image samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"]}]},{"cell_type":"code","metadata":{"id":"eRj04Turs-Ol","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHj35Wfds-VG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iz_gz7_CFY9s","colab_type":"code","outputId":"a847e826-563e-4fbb-c422-68974559f9e0","executionInfo":{"status":"error","timestamp":1576583215965,"user_tz":-180,"elapsed":798434,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":647}},"source":["pyplot.rcParams['figure.figsize'] = (15,15)\n","# size of the latent space\n","latent_dim = 300\n","# create the critic\n","critic = define_critic()\n","# create the generator\n","generator = define_generator(latent_dim)\n","# create the gan\n","\n","critic.trainable = False\n","\n","in_layer = Input(shape = (latent_dim,))\n","in_layer_real_image = Input(shape = (64,64,3))\n","c_layer = in_layer\n","c_layer_im = generator(c_layer)\n","c_layer_fake = critic(c_layer_im)\n","c_layer_real = critic(in_layer_real_image)\n","opt = RMSprop(lr=0.00001)\n","\n","partial_gp_loss = partial(gradient_penalty_loss, averaged_samples = c_layer_im, weight = 10)\n","\n","gan_model = Model([in_layer,in_layer_real_image], [c_layer_real,c_layer_fake,c_layer_real], name = 'define_gan')\n","\n","gan_model.compile(loss=[wasserstein_loss,wasserstein_loss,partial_gp_loss], optimizer=opt)\n","\n","# load image data\n","dataset = load_real_samples()\n","print(dataset.shape)\n","# train model\n","train(generator, critic, gan_model, dataset, latent_dim,n_epochs=50, n_batch=16, n_critic=5)\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2503, 64, 64, 3)\n",">1, c1=-5.715, c2=0.002 g=-15.504 pg=-0.004\n",">2, c1=-19.103, c2=-0.001 g=-21.405 pg=-0.216\n",">3, c1=-25.551, c2=-0.003 g=-27.565 pg=-1.155\n",">4, c1=-29.949, c2=-0.006 g=-33.945 pg=-5.118\n",">5, c1=-34.236, c2=-0.010 g=-37.708 pg=-14.537\n",">6, c1=-36.909, c2=-0.016 g=-40.026 pg=-22.419\n",">7, c1=-40.132, c2=-0.025 g=-41.160 pg=-29.655\n",">8, c1=-42.034, c2=-0.033 g=-45.586 pg=-33.297\n",">9, c1=-45.808, c2=-0.046 g=-42.985 pg=-35.433\n",">10, c1=-47.797, c2=-0.063 g=-48.743 pg=-36.791\n",">11, c1=-48.159, c2=-0.079 g=-52.638 pg=-39.912\n",">12, c1=-51.856, c2=-0.102 g=-51.629 pg=-43.934\n",">13, c1=-52.592, c2=-0.127 g=-56.528 pg=-45.871\n",">14, c1=-56.711, c2=-0.162 g=-55.498 pg=-48.618\n",">15, c1=-58.197, c2=-0.201 g=-59.420 pg=-49.904\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-29d7ba97f382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-32829d92cacc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, c_model, gan_model, dataset, latent_dim, n_epochs, n_batch, n_critic)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mc1_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_loss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                         \u001b[0;31m# generate 'fake' examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                         \u001b[0;31m# update critic model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mc_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-dce52b4572e7>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(generator, latent_dim, n_samples)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# predict outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# create class labels with 1.0 for 'fake'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         callbacks=callbacks)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Ajgj8bp8FZAs","colab_type":"code","outputId":"f26e6343-4c94-42bc-8092-c61e491dad4b","executionInfo":{"status":"ok","timestamp":1576581324191,"user_tz":-180,"elapsed":275,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}},"colab":{"base_uri":"https://localhost:8080/","height":846}},"source":["summarize_performance(1, generator, 300)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1EAAAM9CAYAAAB9s/mLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABCIKAAAgEBEAQAABP8ASXq3chzZAIAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 1080x1080 with 100 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9_5AXzcPkZXP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"23286ce8-2c57-4845-edbe-27d0d3f285d4","executionInfo":{"status":"ok","timestamp":1581502110892,"user_tz":-180,"elapsed":2565,"user":{"displayName":"Екатерина Алейникова","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCvpUXej-yBsbPcPEQVnpBsl3-_-IP6uT1pn3ah=s64","userId":"17881260071329253319"}}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]}]}